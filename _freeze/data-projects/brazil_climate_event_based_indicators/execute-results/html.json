{
  "hash": "7a0abf2f187564c9b0fc1318881660ec",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Climate event-based indicators\"\nbibliography: references.bib\n---\n\n## Introduction\n\nClimate and health research has traditionally represented environmental exposure using nominal meteorological variables, such as mean temperature or total precipitation, included as continuous covariates in epidemiological models. Although these indicators are widely available and straightforward to implement, they often inadequately represent the persistent, extreme, and threshold-exceeding conditions through which climate variability and change affect human health. Many health impacts are driven by discrete climate events - such as heat waves, cold spells, prolonged rainfall, and dry spells - whose effects depend on duration, intensity, and temporal clustering rather than on average conditions alone.\n\nI propose here a method to compute monthly climatological normals and a set of monthly aggregated climate indicators using a climate reanalysis datasets, applied to Brazilian municipalities.\n\n::: callout-tip\nIn a hurry? Jump to the [download](#sec-download) section ;-)\n:::\n\n## Methods\n\nA climatological normal can be computed with data from different sources, including remote sensing sensors and \"area averages or points in gridded datasets\" [@wmoWMOGuidelinesCalculation2017]. Some gridded climatological datasets are available for the Brazilian territory, including the ERA5-Land from Copernicus [@muñoz-sabater2021] and the BR-DWGD dataset [@xavier2022], offering several climatological indicators for a long time range, and continuously updates.\n\nSome research methods demands that climate data must be aggregated in the same spatial and temporal units of other data to be used in statistical models, being a fairly common procedure in epidemiology and economy studies. In order to approach this issue, spatial gridded data can be aggregated using *zonal statistics* [@saldanhaZonalStatisticsDatasets2024].\n\nThe updated climate zonal statistics datasets for the Brazilian municipalities from ERA5-Land was used to compute climatological normals and monthly event indicators.\n\nFor this, an R package named [{climindi}](https://rfsaldanha.github.io/climindi) was created. The package provides helper functions to compute climatological normals and event-based climate indicators in a [tidy](https://www.tidyverse.org) way.\n\n### Normal indicators\n\nThe {climindi} package computes the average, 10th and 90th percentile as climatological normals.\n\n### Event-based indicators\n\nThe {climindi} package present functions to compute the following statistics for time-aggregated data: count of data points, average, median, standard deviation, standard error, maximum and minimum values, the 10th, 25th, 75th and 90th percentiles, and event-based indicators, listed bellow.\n\n-   Precipitation\n    -   Rain spells: count of rain spells occurrences, with 3 and 5 or more consecutive days with rain above the climatological normal average value\n    -   Count of days with precipitation above 1mm, 5mm, 10mm, 50mm, and 100mm\n    -   Count of sequences of 3 days, 5 days, 10 days, 15 days, 20 days, and 25 days or more without precipitation\n-   Maximum temperature\n    -   Heat waves: Count of heat waves occurrences, with 3 and 5 or more consecutive days with maximum temperature above the climatological normal value plus 5 Celsius degrees\n    -   Hot days: count of warm days, when the maximum temperature is above the normal 90th percentile\n    -   Count of days with temperatures above or equal to 25, 30, 35, and 40 Celsius degrees\n-   Minimum temperature\n    -   Cold spells: count of cold spells occurrences, with 3 and 5 or more consecutive days with minimum temperature bellow the climatological normal value minus 5 Celsius degrees\n    -   Cold days: count of cold days, when the minimum temperature is bellow the normal 10th percentile\n    -   Count of days with temperatures bellow or equal to 0, 5, 10, 15, and 20 Celsius degrees\n-   Relative humidity\n    -   Count of dry spells occurrences, with 3 and 5 or more consecutive days with relative humidity bellow the climatological normal value minus 10 percent\n    -   Count of wet spells occurrences, with 3 and 5 or more consecutive days with relative humidity above the climatological normal value plus 10 percent\n    -   Count of dry days, when the relative humidity is bellow the normal 10th percentile\n    -   Count of wet days, when the relative humidity is above the normal 90th percentile\n    -   Count of days with relative humidity between 21% and 30% (Attention level)\n    -   Count of days with relative humidity between 12% and 20% (Alert level)\n    -   Count of days with relative humidity bellow 12% (Emergence level)\n-   Wind speed\n    -   Count of sequences of 3 and 5 days or more with wind speed bellow the climatological average normal\n    -   Count of sequences of 3 and 5 days or more with wind speed above the climatological average normal\n\n::: callout-important\nThe package functions needs data in the correct units. Please certify that your data is in the correct unit before running the functions.\n:::\n\n### Data source\n\nThe zonal statistics for the Brazilian municipalities computed with the Copernicus ERA5-Land is described [here](https://rfsaldanha.github.io/data-projects/brazil-climate-zonal-indicators.html#zonal-era5-land). We can use the [{zendown}](https://rfsaldanha.github.io/zendown/) package to download the data files directly from from Zenodo.\n\nWe will use the data from 1981 to 2010 to compute the climatological normals and the data from 2011 to compute climate event-based indicators.\n\n### Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(arrow)\nlibrary(readr)\nlibrary(climindi) # http://rfsaldanha.github.io/climindi/\nlibrary(zendown) # https://rfsaldanha.github.io/zendown/\n```\n:::\n\n\n::: callout-warning\nTo perform those computations, I needed to increase the envinroment variable `R_MAX_VSIZE` to 100GB, as explained [here](https://stackoverflow.com/questions/51248293/error-vector-memory-exhausted-limit-reached-r-3-5-0-macos).\n:::\n\n### Precipitation (mm)\n\n#### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprec_1950_2022 <- zen_file(10036212, \"total_precipitation_sum.parquet\")\nprec_2023 <- zen_file(10947952, \"total_precipitation_sum.parquet\")\nprec_2024 <- zen_file(15748125, \"total_precipitation_sum.parquet\")\nprec_2025 <- zen_file(18257037, \"total_precipitation_sum.parquet\")\n\nprec_data <- open_dataset(\n  sources = c(prec_1950_2022, prec_2023, prec_2024, prec_2025)\n) |>\n  # Average precipitation\n  filter(name == \"total_precipitation_sum_mean\") |>\n  # Time filter\n  filter(date >= as.Date(\"1981-01-01\")) |>\n  # Unit conversion from m to mm\n  mutate(value = round(value * 1000, digits = 2)) |>\n  select(-name) |>\n  arrange(code_muni, date) |>\n  collect()\n```\n:::\n\n\n#### Climatological normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprec_normal <- prec_data |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Group by id variable and month\n  group_by(code_muni, month) |>\n  # Compute normal\n  summarise_normal(\n    date_var = date,\n    value_var = value,\n    year_start = 1981,\n    year_end = 2010\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Climatological indicators\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprec_indi <- prec_data |>\n  # Identify year\n  mutate(year = year(date)) |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Filter year\n  filter(year >= 2011) |>\n  # Create wave variables\n  dplyr::group_by(code_muni) |>\n  dplyr::arrange(date) |>\n  add_wave(\n    normals_df = prec_normal,\n    threshold = 0,\n    threshold_cond = \"gte\",\n    size = 3,\n    var_name = \"rs3\"\n  ) |>\n  add_wave(\n    normals_df = prec_normal,\n    threshold = 0,\n    threshold_cond = \"gte\",\n    size = 5,\n    var_name = \"rs5\"\n  ) |>\n  dplyr::ungroup() |>\n  # Group by id variable, year and month\n  group_by(code_muni, year, month) |>\n  # Compute precipitation indicators\n  summarise_precipitation(\n    value_var = value,\n    normals_df = prec_normal\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Export\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_parquet(x = prec_normal, sink = \"prec_normal.parquet\")\nwrite_csv2(x = prec_normal, file = \"prec_normal.csv\")\nwrite_parquet(x = prec_indi, sink = \"prec_indi.parquet\")\nwrite_csv2(x = prec_indi, file = \"prec_indi.csv\")\n```\n:::\n\n\n### Maximum temperature (°C)\n\n#### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmax_1950_2022 <- zen_file(10036212, \"2m_temperature_max.parquet\")\ntmax_2023 <- zen_file(10947952, \"2m_temperature_max.parquet\")\ntmax_2024 <- zen_file(15748125, \"2m_temperature_max.parquet\")\n\ntmax_data <- open_dataset(sources = c(tmax_1950_2022, tmax_2023, tmax_2024)) |>\n  # Average maximum temperature\n  filter(name == \"2m_temperature_max_mean\") |>\n  # Time filter\n  filter(date >= as.Date(\"1961-01-01\")) |>\n  filter(date <= as.Date(\"2024-12-31\")) |>\n  # Unit conversion form Kelvin to Celsius degrees\n  mutate(value = round(value - 273.15, digits = 2)) |>\n  select(-name) |>\n  arrange(code_muni, date) |>\n  collect()\n```\n:::\n\n\n#### Climatological normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmax_normal <- tmax_data |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Group by id variable and month\n  group_by(code_muni, month) |>\n  # Compute normal\n  summarise_normal(\n    date_var = date,\n    value_var = value,\n    year_start = 1961,\n    year_end = 1990\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Climatological indicators\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmax_indi <- tmax_data |>\n  # Identify year\n  mutate(year = year(date)) |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Filter year\n  filter(year >= 1991) |>\n  # Group by id variable, year and month\n  group_by(code_muni, year, month) |>\n  # Compute precipitation indicators\n  summarise_temp_max(\n    value_var = value,\n    normals_df = tmax_normal\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Export\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_parquet(x = tmax_normal, sink = \"tmax_normal.parquet\")\nwrite_csv2(x = tmax_normal, file = \"tmax_normal.csv\")\nwrite_parquet(x = tmax_indi, sink = \"tmax_indi.parquet\")\nwrite_csv2(x = tmax_indi, file = \"tmax_indi.csv\")\n```\n:::\n\n\n### Minimum temperature (°C)\n\n#### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmin_1950_2022 <- zen_file(10036212, \"2m_temperature_min.parquet\")\ntmin_2023 <- zen_file(10947952, \"2m_temperature_min.parquet\")\ntmin_2024 <- zen_file(15748125, \"2m_temperature_min.parquet\")\n\ntmin_data <- open_dataset(sources = c(tmin_1950_2022, tmin_2023, tmin_2024)) |>\n  # Average minimum temperature\n  filter(name == \"2m_temperature_min_mean\") |>\n  # Filter period\n  filter(date >= as.Date(\"1961-01-01\")) |>\n  filter(date <= as.Date(\"2024-12-31\")) |>\n  # Unit conversion\n  mutate(value = round(value - 273.15, digits = 2)) |>\n  select(-name) |>\n  arrange(code_muni, date) |>\n  collect()\n```\n:::\n\n\n#### Climatological normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmin_normal <- tmin_data |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Group by id variable and month\n  group_by(code_muni, month) |>\n  # Compute normal\n  summarise_normal(\n    date_var = date,\n    value_var = value,\n    year_start = 1961,\n    year_end = 1990\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Climatologial indicators\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmin_indi <- tmin_data |>\n  # Identify year\n  mutate(year = year(date)) |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Filter year\n  filter(year >= 1991) |>\n  # Group by id variable, year and month\n  group_by(code_muni, year, month) |>\n  # Compute precipitation indicators\n  summarise_temp_min(\n    value_var = value,\n    normals_df = tmin_normal\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Export\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_parquet(x = tmin_normal, sink = \"tmin_normal.parquet\")\nwrite_csv2(x = tmin_normal, file = \"tmin_normal.csv\")\nwrite_parquet(x = tmin_indi, sink = \"tmin_indi.parquet\")\nwrite_csv2(x = tmin_indi, file = \"tmin_indi.csv\")\n```\n:::\n\n\n### Wind speed at 2m height (m/s)\n\n#### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwu_1950_2022 <- zen_file(10036212, \"10m_u_component_of_wind_mean.parquet\")\nwu_2023 <- zen_file(10947952, \"10m_u_component_of_wind_mean.parquet\")\nwu_2024 <- zen_file(15748125, \"10m_u_component_of_wind_mean.parquet\")\n\nwv_1950_2022 <- zen_file(10036212, \"10m_v_component_of_wind_mean.parquet\")\nwv_2023 <- zen_file(10947952, \"10m_v_component_of_wind_mean.parquet\")\nwv_2024 <- zen_file(15748125, \"10m_v_component_of_wind_mean.parquet\")\n\nwu_data <- open_dataset(sources = c(wu_1950_2022, wu_2023, wu_2024)) |>\n  # Average minimum temperature\n  filter(name == \"10m_u_component_of_wind_mean_mean\") |>\n  # Filter period\n  filter(date >= as.Date(\"1961-01-01\")) |>\n  filter(date <= as.Date(\"2024-12-31\")) |>\n  select(-name) |>\n  arrange(code_muni, date) |>\n  collect()\n\nwv_data <- open_dataset(sources = c(wv_1950_2022, wv_2023, wv_2024)) |>\n  # Average minimum temperature\n  filter(name == \"10m_u_component_of_wind_mean_mean\") |>\n  # Filter period\n  filter(date >= as.Date(\"1961-01-01\")) |>\n  filter(date <= as.Date(\"2024-12-31\")) |>\n  select(-name) |>\n  arrange(code_muni, date) |>\n  collect()\n\n\nu2_data <- zen_file(13906834, \"u2_3.2.3.parquet\") |>\n  open_dataset() |>\n  filter(name == \"u2_3.2.3_mean\") |>\n  filter(date >= as.Date(\"1961-01-01\")) |>\n  filter(date <= as.Date(\"2024-12-31\")) |>\n  select(-name) |>\n  collect()\n```\n:::\n\n\n#### Climatological normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nu2_normal <- u2_data |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Group by id variable and month\n  group_by(code_muni, month) |>\n  # Compute normal\n  summarise_normal(\n    date_var = date,\n    value_var = value,\n    year_start = 1961,\n    year_end = 1990\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Climatological indicators\n\n\n::: {.cell}\n\n```{.r .cell-code}\nu2_indi <- u2_data |>\n  # Identify year\n  mutate(year = year(date)) |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Filter year\n  filter(year >= 1991) |>\n  # Group by id variable, year and month\n  group_by(code_muni, year, month) |>\n  # Compute precipitation indicators\n  summarise_windspeed(\n    value_var = value,\n    normals_df = u2_normal\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Export\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_parquet(x = u2_normal, sink = \"u2_normal.parquet\")\nwrite_csv2(x = u2_normal, file = \"u2_normal.csv\")\nwrite_parquet(x = u2_indi, sink = \"u2_indi.parquet\")\nwrite_csv2(x = u2_indi, file = \"u2_indi.csv\")\n```\n:::\n\n\n### Relative humidity (%)\n\n#### Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrh_data <- zen_file(13906834, \"RH_3.2.3.parquet\") |>\n  open_dataset() |>\n  filter(name == \"RH_3.2.3_mean\") |>\n  filter(date >= as.Date(\"1961-01-01\")) |>\n  filter(date <= as.Date(\"2024-12-31\")) |>\n  select(-name) |>\n  collect()\n```\n:::\n\n\n#### Normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrh_normal <- rh_data |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Group by id variable and month\n  group_by(code_muni, month) |>\n  # Compute normal\n  summarise_normal(\n    date_var = date,\n    value_var = value,\n    year_start = 1961,\n    year_end = 1990\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Indicators\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrh_indi <- rh_data |>\n  # Identify year\n  mutate(year = year(date)) |>\n  # Identify month\n  mutate(month = month(date)) |>\n  # Filter year\n  filter(year >= 1991) |>\n  # Group by id variable, year and month\n  group_by(code_muni, year, month) |>\n  # Compute precipitation indicators\n  summarise_rel_humidity(\n    value_var = value,\n    normals_df = rh_normal\n  ) |>\n  # Ungroup\n  ungroup()\n```\n:::\n\n\n#### Export\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_parquet(x = rh_normal, sink = \"rh_normal.parquet\")\nwrite_csv2(x = rh_normal, file = \"rh_normal.csv\")\nwrite_parquet(x = rh_indi, sink = \"rh_indi.parquet\")\nwrite_csv2(x = rh_indi, file = \"rh_indi.csv\")\n```\n:::\n\n\n## Results and dataset download {#sec-download}\n\nThe climatological normals and aggregated indicators of Brazilian municipalities can be downloaded from Zenodo on CSV and parquet formats. Click the link bellow to access and download the data.\n\n[![](https://zenodo.org/badge/DOI/10.5281/zenodo.15519719.svg)](https://doi.org/10.5281/zenodo.15519719)\n\nYou can also download the dataset directly from R, using the [{zendown}](https://rfsaldanha.github.io/zendown/) package.\n\nLet's check some results.\n\n### Maximum temperature, Rio de Janeiro, RJ, 2023\n\n#### Observed and normal\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmax_data <- zen_file(13906834, \"Tmax_3.2.3.parquet\") |>\n  open_dataset() |>\n  filter(name == \"Tmax_3.2.3_mean\") |>\n  filter(code_muni == 3304557) |>\n  filter(date >= as.Date(\"2023-01-01\")) |>\n  filter(date <= as.Date(\"2023-12-31\")) |>\n  select(-name) |>\n  collect()\n\ntmax_normal <- zen_file(15519719, \"tmax_normal.parquet\") |>\n  open_dataset() |>\n  filter(code_muni == 3304557) |>\n  collect()\n```\n:::\n\n\n\n::: {.cell .preview-image}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\n\ntmax_normal_exp <- tmax_normal |>\n  mutate(date = as_date(paste0(\"2023-\", month, \"-01\"))) |>\n  group_by(month) %>%\n  expand(\n    date = seq.Date(\n      floor_date(date, unit = \"month\"),\n      ceiling_date(date, unit = \"month\") - days(1),\n      by = \"day\"\n    ),\n    normal_mean,\n    normal_p10,\n    normal_p90\n  ) |>\n  pivot_longer(cols = starts_with(\"normal_\")) |>\n  mutate(name = substr(name, 8, 100))\n\nggplot() +\n  geom_line(data = tmax_data, aes(x = date, y = value)) +\n  geom_line(data = tmax_normal_exp, aes(x = date, y = value, color = name)) +\n  theme_bw() +\n  labs(\n    title = \"Maximum temperature and climatological normal\",\n    subtitle = \"Rio de Janeiro, RJ\",\n    color = \"Normal (1961-1990)\",\n    x = \"Date\",\n    y = \"Celsius degrees\"\n  ) +\n  theme(legend.position = \"bottom\", legend.direction = \"horizontal\")\n```\n:::\n\n\n#### Indicators\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(gt)\n\nzen_file(15519719, \"tmax_indi.parquet\") |>\n  open_dataset() |>\n  filter(code_muni == 3304557) |>\n  filter(year == 2023) |>\n  select(-code_muni, -year) |>\n  collect() |>\n  gt() |>\n  fmt_number(\n    columns = where(is.double),\n    decimals = 2,\n    use_seps = FALSE\n  )\n```\n:::\n\n\n## Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.5.2 (2025-10-31)\n os       macOS Tahoe 26.2\n system   aarch64, darwin20\n ui       X11\n language (EN)\n collate  en_US.UTF-8\n ctype    en_US.UTF-8\n tz       America/Sao_Paulo\n date     2026-02-09\n pandoc   3.6.3 @ /Applications/Positron.app/Contents/Resources/app/quarto/bin/tools/aarch64/ (via rmarkdown)\n quarto   1.8.27 @ /Applications/Positron.app/Contents/Resources/app/quarto/bin/quarto\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version  date (UTC) lib source\n arrow       * 22.0.0.1 2025-12-23 [1] CRAN (R 4.5.2)\n assertthat    0.2.1    2019-03-21 [1] CRAN (R 4.5.0)\n bit           4.6.0    2025-03-06 [1] CRAN (R 4.5.0)\n bit64         4.6.0-1  2025-01-16 [1] CRAN (R 4.5.0)\n cli           3.6.5    2025-04-23 [1] CRAN (R 4.5.0)\n climindi    * 0.2.0    2026-02-09 [1] Github (rfsaldanha/climindi@9eb3d5f)\n digest        0.6.39   2025-11-19 [1] CRAN (R 4.5.2)\n dplyr       * 1.2.0    2026-02-03 [1] CRAN (R 4.5.2)\n evaluate      1.0.5    2025-08-27 [1] CRAN (R 4.5.0)\n fastmap       1.2.0    2024-05-15 [1] CRAN (R 4.5.0)\n generics      0.1.4    2025-05-09 [1] CRAN (R 4.5.0)\n glue          1.8.0    2024-09-30 [1] CRAN (R 4.5.0)\n hms           1.1.4    2025-10-17 [1] CRAN (R 4.5.0)\n htmltools     0.5.9    2025-12-04 [1] CRAN (R 4.5.2)\n htmlwidgets   1.6.4    2023-12-06 [1] CRAN (R 4.5.0)\n jsonlite      2.0.0    2025-03-27 [1] CRAN (R 4.5.0)\n knitr         1.51     2025-12-20 [1] CRAN (R 4.5.2)\n lifecycle     1.0.5    2026-01-08 [1] CRAN (R 4.5.2)\n lubridate   * 1.9.5    2026-02-04 [1] CRAN (R 4.5.2)\n magrittr      2.0.4    2025-09-12 [1] CRAN (R 4.5.0)\n otel          0.2.0    2025-08-29 [1] CRAN (R 4.5.0)\n pillar        1.11.1   2025-09-17 [1] CRAN (R 4.5.0)\n pkgconfig     2.0.3    2019-09-22 [1] CRAN (R 4.5.0)\n purrr         1.2.1    2026-01-09 [1] CRAN (R 4.5.2)\n R6            2.6.1    2025-02-15 [1] CRAN (R 4.5.0)\n readr       * 2.1.6    2025-11-14 [1] CRAN (R 4.5.2)\n rlang         1.1.7    2026-01-09 [1] CRAN (R 4.5.2)\n rmarkdown     2.30     2025-09-28 [1] CRAN (R 4.5.0)\n sessioninfo   1.2.3    2025-02-05 [1] CRAN (R 4.5.0)\n tibble        3.3.1    2026-01-11 [1] CRAN (R 4.5.2)\n tidyselect    1.2.1    2024-03-11 [1] CRAN (R 4.5.0)\n timechange    0.4.0    2026-01-29 [1] CRAN (R 4.5.2)\n tzdb          0.5.0    2025-03-15 [1] CRAN (R 4.5.0)\n vctrs         0.7.1    2026-01-23 [1] CRAN (R 4.5.2)\n xfun          0.56     2026-01-18 [1] CRAN (R 4.5.2)\n yaml          2.3.12   2025-12-10 [1] CRAN (R 4.5.2)\n zendown     * 0.1.0    2024-05-21 [1] CRAN (R 4.5.0)\n\n [1] /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n:::\n",
    "supporting": [
      "brazil_climate_event_based_indicators_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}